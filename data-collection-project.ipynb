{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/omarmostafataha/data-collection-project?scriptVersionId=143190226\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# For Arab football fans","metadata":{}},{"cell_type":"markdown","source":"This is a Python code to collect data about matches played in 2023 from the YallaKora website. YallaKora is a popular Arabic-language sports news and information website that covers various sports, including football, basketball, and more. It provides news, live scores, match results, statistics, and other sports-related content for audiences interested in sports, particularly in the Arab world and the Middle East. Users can find information about football leagues, teams, players, and matches, among other sports-related topics, on YallaKora website.","metadata":{}},{"cell_type":"code","source":"def card_matches(champ_card, input_date):\n    \n    # extract card elements --> champ title and matches (title-->div, matches-->ul)\n    card_contents = champ_card.contents\n    card_contents = [item for item in card_contents if item != '\\n']\n    \n    title_div = card_contents[0]\n    matches_list = card_contents[1]\n    \n    # extract champ title from title_div\n    title = title_div.find('h2').text.strip()\n    \n    # extract matches from matches_list \n    matches = matches_list.find_all('li')\n    \n    for match in matches:\n        \n        # extract each match data\n        match_data = match.find('div',{'class':'teamsData'}).contents\n        match_data = [item for item in match_data if item != '\\n']\n        teamA = match_data[1].text.strip() \n        teamB = match_data[5].text.strip()\n        result_time = match_data[3].text.strip().replace('\\n','',2).split('\\n')\n        \n        # store match data in global lists\n        team1.append(teamA)\n        team2.append(teamB)\n        result.append(result_time[0])\n        time.append(result_time[1])\n        championship.append(title)\n        date.append(input_date)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:57:34.211511Z","iopub.execute_input":"2023-09-16T07:57:34.211895Z","iopub.status.idle":"2023-09-16T07:57:34.252382Z","shell.execute_reply.started":"2023-09-16T07:57:34.211865Z","shell.execute_reply":"2023-09-16T07:57:34.251046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scrap(input_date):\n    # define the page you want to scrap\n    url = f'https://www.yallakora.com/match-center/%D9%85%D8%B1%D9%83%D8%B2-%D8%A7%D9%84%D9%85%D8%A8%D8%A7%D8%B1%D9%8A%D8%A7%D8%AA?date={input_date}#'\n\n    # sending request\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Check for HTTP errors\n    except Exception as e:\n        print(f\"An error occurred while making the request: {e}\")\n        \n    if response.status_code == 200: \n        # extracting the page content\n        content = response.content\n        soup = BeautifulSoup(content,'lxml')\n\n        # extract championship cards\n        champ_cards = soup.find_all('div', {'class':'matchCard'})   \n\n        # extract matches data\n        for card in champ_cards:\n            card_matches(card, input_date)\n            \n    else:\n        print(f\"Failed to retrieve the webpage [date: {input_date}] . Status code: {response.status_code}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:57:34.255029Z","iopub.execute_input":"2023-09-16T07:57:34.255526Z","iopub.status.idle":"2023-09-16T07:57:34.265929Z","shell.execute_reply.started":"2023-09-16T07:57:34.255483Z","shell.execute_reply":"2023-09-16T07:57:34.264531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import libraries\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# define empty lists \nteam1 = []\nteam2 = []\nresult = []\ntime = []\nchampionship = []\ndate = []\n\n# Define a date range\nstart_date = datetime(2023, 1, 1)  # Start date (y,m,d)\nend_date = datetime(2023, 12, 31)   # End date (y,m,d) \ncurrent_date = start_date\n\n# loop and scrap the pages in the date range\nwhile current_date <= end_date:\n    formatted_date = current_date.strftime(\"%m/%d/%Y\")  # Format the date as needed\n    scrap(formatted_date)  # Call the scrap function with the formatted date\n    current_date += timedelta(days=1)  # Move to the next date","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:57:34.267294Z","iopub.execute_input":"2023-09-16T07:57:34.267619Z","iopub.status.idle":"2023-09-16T08:14:22.97552Z","shell.execute_reply.started":"2023-09-16T07:57:34.267591Z","shell.execute_reply":"2023-09-16T08:14:22.97453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dataframe with all the lists\ndf = pd.DataFrame({'Championship':championship, 'Team 1':team1, 'Team 2':team2, 'Match Time':time, 'Match result':result, \"Date\":date})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:14:22.978635Z","iopub.execute_input":"2023-09-16T08:14:22.980255Z","iopub.status.idle":"2023-09-16T08:14:23.019276Z","shell.execute_reply.started":"2023-09-16T08:14:22.980205Z","shell.execute_reply":"2023-09-16T08:14:23.018279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:14:23.020402Z","iopub.execute_input":"2023-09-16T08:14:23.02094Z","iopub.status.idle":"2023-09-16T08:14:23.027706Z","shell.execute_reply.started":"2023-09-16T08:14:23.020909Z","shell.execute_reply":"2023-09-16T08:14:23.026701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the data in an excel file\ndf.to_excel('matches_2023.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:01:38.518Z","iopub.execute_input":"2023-09-16T09:01:38.518441Z","iopub.status.idle":"2023-09-16T09:01:39.617419Z","shell.execute_reply.started":"2023-09-16T09:01:38.51841Z","shell.execute_reply":"2023-09-16T09:01:39.615815Z"},"trusted":true},"execution_count":null,"outputs":[]}]}